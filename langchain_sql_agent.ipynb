{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LangChain Agent Tutorial: Querying Tabular Data with SQL\n",
                "\n",
                "This notebook demonstrates how to build a LangChain agent capable of querying tabular data (stored in an Excel file) using SQL. We'll load the data into a Pandas DataFrame, store it in a SQLite database, and then use LangChain's `langgraph` library to create an agent that can:\n",
                "\n",
                "1.  Understand a natural language question.\n",
                "2.  Generate a SQL query based on the question and the database schema.\n",
                "3.  Execute the SQL query against the database.\n",
                "4.  Generate a natural language answer based on the query result."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install Dependencies\n",
                "\n",
                "First, we need to install the required Python libraries. \n",
                "\n",
                "* `pandas`: For data manipulation and reading the Excel file.\n",
                "* `langchain`: The core LangChain library.\n",
                "* `langchain-experimental`: Contains experimental LangChain features, including agent toolkits.\n",
                "* `langchain-openai`: For interacting with OpenAI models (or compatible APIs).\n",
                "* `langchain-community`: Provides community integrations, including the SQL Database tool.\n",
                "* `langchain-core`: Core abstractions for LangChain.\n",
                "* `langgraph`: A library for building stateful, multi-actor applications with LLMs (used here to define the agent's flow).\n",
                "* `sqlalchemy`: Needed for interacting with the SQL database.\n",
                "* `openpyxl`: Required by pandas to read `.xlsx` files.\n",
                "* `typing_extensions`: Provides extended type hinting capabilities.\n",
                "* `ipython`: Used for displaying images within the notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install pandas langchain langchain-experimental langchain-openai langchain-community langchain-core langgraph sqlalchemy openpyxl typing_extensions ipython"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Import Initial Libraries\n",
                "\n",
                "Import the initial set of libraries needed, including pandas for data handling and LangChain components for agents and LLMs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from langchain.agents.agent_types import AgentType\n",
                "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
                "from langchain_openai import ChatOpenAI"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Data\n",
                "\n",
                "Load the course information from an Excel file into a Pandas DataFrame. Then, display a random sample of 5 rows to inspect the data structure and content. Ensure the Excel file 'Cleaned_Course_Masterlist_Info.xlsx' is in the same directory as this notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Data\n",
                "training_df = pd.read_excel(\"Cleaned_Course_Masterlist_Info.xlsx\")\n",
                "training_df.sample(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Store Data in SQLite Database\n",
                "\n",
                "To enable SQL querying by the agent, we store the Pandas DataFrame in a SQLite database.\n",
                "\n",
                "* Import necessary libraries: `SQLDatabase` from `langchain_community.utilities` and `create_engine` from `sqlalchemy`.\n",
                "* Create a SQLAlchemy engine connected to a local SQLite database file named `training.db`.\n",
                "* Use the DataFrame's `to_sql` method to write the data to a table named \"training\" in the database. `index=False` prevents writing the DataFrame index as a column."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community.utilities import SQLDatabase\n",
                "from sqlalchemy import create_engine\n",
                "\n",
                "engine = create_engine(\"sqlite:///training.db\")\n",
                "training_df.to_sql(\"training\", engine, index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Initialize LangChain SQL Database Connection\n",
                "\n",
                "Create a LangChain `SQLDatabase` object, wrapping the SQLAlchemy engine. This allows LangChain components to interact with the database.\n",
                "\n",
                "* Instantiate `SQLDatabase` using the created engine.\n",
                "* Print the database dialect (e.g., 'sqlite').\n",
                "* Print the names of tables accessible via this connection (should include 'training').\n",
                "* Run a sample SQL query directly using `db.run` to verify the connection and retrieve some data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "db = SQLDatabase(engine=engine)\n",
                "print(db.dialect)\n",
                "print(db.get_usable_table_names())\n",
                "print(db.run(\"SELECT * FROM training WHERE SGDCostperpax_25_26 > 1000;\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Set Up Language Model (LLM)\n",
                "\n",
                "Configure the connection to the Language Model. This example uses `ChatOpenAI` but points to a local server URL (`http://127.0.0.1:1235/v1`) and specifies a local model path. \n",
                "\n",
                "* Import necessary modules (`getpass`, `os`, `ChatOpenAI`).\n",
                "* (Commented out) Code to optionally get an API key securely if needed for a cloud-based service.\n",
                "* Instantiate `ChatOpenAI`, providing the base URL, a placeholder API key (as it's a local server), and the model identifier."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import getpass\n",
                "import os\n",
                "\n",
                "#if not os.environ.get(\"TOGETHER_API_KEY\"):\n",
                "#  os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass(\"Enter API key for Together AI: \")\n",
                "\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "llm = ChatOpenAI(\n",
                "    base_url=\"http://127.0.0.1:1235/v1\",\n",
                "    api_key=\"token-abc123\",\n",
                "    model=r\"/home/otb-02/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct-GPTQ-Int4/snapshots/e9c932ac1893a49ae0fc497ad6e1e86e2e39af20\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Define SQL Query Generation Prompt\n",
                "\n",
                "Create a prompt template specifically designed to instruct the LLM on how to generate SQL queries based on a user's question and the database schema.\n",
                "\n",
                "* Import `ChatPromptTemplate`.\n",
                "* Define a multi-line string template with placeholders for `dialect`, `top_k` (max results), `table_info`, and the user's `input`.\n",
                "* The template guides the LLM to create syntactically correct SQL for the given dialect, limit results, select relevant columns only, use existing columns/tables, and format the output as JSON with a \"query\" field."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.prompts.chat import ChatPromptTemplate\n",
                "\n",
                "# Convert the text template into a ChatPromptTemplate\n",
                "query_prompt_template = ChatPromptTemplate.from_template(\n",
                "    '''\n",
                "    Given an input question, create a syntactically correct {dialect} query to run to help find the answer. Unless the user specifies in his question a specific number of examples they wish to obtain, always limit your query to at most {top_k} results. You can order the results by a relevant column to return the most interesting examples in the database.\n",
                "\n",
                "    Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
                "\n",
                "    The query should be formatted as JSON with a single field \"query\":\n",
                "\n",
                "    {{\n",
                "      \"query\": \"SELECT COUNT(*) FROM Database;\"\n",
                "    }}\n",
                "\n",
                "    Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
                "\n",
                "    Only use the following tables:\n",
                "    {table_info}\n",
                "\n",
                "    Question: {input}\n",
                "    '''\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Define Agent State\n",
                "\n",
                "Define the structure for the agent's state using `TypedDict`. The state will hold information passed between different steps (nodes) in the agent's workflow.\n",
                "\n",
                "* Import `TypedDict` from `typing_extensions`.\n",
                "* Define a class `State` inheriting from `TypedDict`.\n",
                "* Specify the fields the state will contain: `question` (user's input), `query` (generated SQL), `result` (SQL execution output), and `answer` (final natural language response)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing_extensions import TypedDict\n",
                "\n",
                "\n",
                "class State(TypedDict):\n",
                "    question: str\n",
                "    query: str\n",
                "    result: str\n",
                "    answer: str"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Define Agent Node: Write Query\n",
                "\n",
                "Create the first node for the agent graph. This node takes the current state (containing the question) and generates the SQL query.\n",
                "\n",
                "* Import `Annotated` from `typing_extensions`.\n",
                "* Define a `QueryOutput` TypedDict to specify the expected JSON structure (a single \"query\" field) from the LLM for this step.\n",
                "* Define the `write_query` function that accepts the `State`.\n",
                "* Inside the function:\n",
                "    * Invoke the `query_prompt_template` with necessary details (dialect, top_k, table_info, question from the state).\n",
                "    * Use `llm.with_structured_output(QueryOutput)` to ensure the LLM's response conforms to the `QueryOutput` structure.\n",
                "    * Invoke the structured LLM with the formatted prompt.\n",
                "    * Return a dictionary containing the generated query to update the state's \"query\" field."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing_extensions import Annotated\n",
                "\n",
                "\n",
                "\n",
                "class QueryOutput(TypedDict):\n",
                "    \"\"\"Generated SQL query.\"\"\"\n",
                "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
                "\n",
                "\n",
                "def write_query(state: State):\n",
                "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
                "    prompt = query_prompt_template.invoke(\n",
                "        {\n",
                "            \"dialect\": db.dialect,\n",
                "            \"top_k\": 10,\n",
                "            \"table_info\": db.get_table_info(),\n",
                "            \"input\": state[\"question\"],\n",
                "        }\n",
                "    )\n",
                "    structured_llm = llm.with_structured_output(QueryOutput)\n",
                "    result = structured_llm.invoke(prompt)\n",
                "    return {\"query\": result[\"query\"]}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Test `write_query` Node\n",
                "\n",
                "Test the `write_query` function independently by providing a sample state dictionary containing a question."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "write_query({\"question\": \"How many category OSINT courses are there?\"})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Define Agent Node: Execute Query\n",
                "\n",
                "Create the second node for the agent graph. This node takes the state (containing the generated SQL query) and executes it against the database.\n",
                "\n",
                "* Import `QuerySQLDatabaseTool` from `langchain_community.tools.sql_database.tool`.\n",
                "* Define the `execute_query` function that accepts the `State`.\n",
                "* Inside the function:\n",
                "    * Instantiate `QuerySQLDatabaseTool`, providing the `db` connection object.\n",
                "    * Invoke the tool with the SQL query from the state's \"query\" field.\n",
                "    * Return a dictionary containing the query result to update the state's \"result\" field."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
                "\n",
                "\n",
                "def execute_query(state: State):\n",
                "    \"\"\"Execute SQL query.\"\"\"\n",
                "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
                "    return {\"result\": execute_query_tool.invoke(state[\"query\"])}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Test `execute_query` Node\n",
                "\n",
                "Test the `execute_query` function independently by providing a sample state dictionary containing a SQL query."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "execute_query({'query': \"SELECT COUNT(*) FROM training WHERE Category = 'OSINT';\"})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Define Agent Node: Generate Answer\n",
                "\n",
                "Create the final node for the agent graph. This node takes the state (containing the original question, the SQL query, and the SQL result) and generates a natural language answer.\n",
                "\n",
                "* Define the `generate_answer` function that accepts the `State`.\n",
                "* Inside the function:\n",
                "    * Construct a prompt string containing the original question, the generated SQL query, and the SQL result as context.\n",
                "    * Invoke the base LLM (`llm`) with this context prompt.\n",
                "    * Return a dictionary containing the LLM's response content to update the state's \"answer\" field."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_answer(state: State):\n",
                "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
                "    prompt = (\n",
                "        \"Given the following user question, corresponding SQL query, \"\n",
                "        \"and SQL result, answer the user question.\\n\\n\"\n",
                "        f'Question: {state[\"question\"]}\\n'\n",
                "        f'SQL Query: {state[\"query\"]}\\n'\n",
                "        f'SQL Result: {state[\"result\"]}'\n",
                "    )\n",
                "    response = llm.invoke(prompt)\n",
                "    return {\"answer\": response.content}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Build Agent Graph\n",
                "\n",
                "Assemble the defined nodes into a sequential graph using `langgraph`.\n",
                "\n",
                "* Import `START` and `StateGraph` from `langgraph.graph`.\n",
                "* Instantiate `StateGraph` with the defined `State` type.\n",
                "* Use `add_sequence` to define the flow: `write_query` -> `execute_query` -> `generate_answer`.\n",
                "* Explicitly add an edge from the special `START` node to the first node (`write_query`).\n",
                "* Compile the graph builder into a runnable `graph` object."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langgraph.graph import START, StateGraph\n",
                "\n",
                "graph_builder = StateGraph(State).add_sequence(\n",
                "    [write_query, execute_query, generate_answer]\n",
                ")\n",
                "graph_builder.add_edge(START, \"write_query\")\n",
                "graph = graph_builder.compile()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Visualize Graph (Optional)\n",
                "\n",
                "Display a visual representation of the compiled agent graph.\n",
                "\n",
                "* Import `Image` and `display` from `IPython.display`.\n",
                "* Call `graph.get_graph().draw_mermaid_png()` to generate a PNG image of the graph.\n",
                "* Use `display` to show the image in the notebook output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import Image, display\n",
                "\n",
                "display(Image(graph.get_graph().draw_mermaid_png()))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 14. Run the Agent\n",
                "\n",
                "Execute the compiled graph (the agent) with a specific question.\n",
                "\n",
                "* Import `pprint` for nicely formatted output.\n",
                "* Use `graph.stream()` to run the agent. Provide the initial state as a dictionary containing the user's `question`.\n",
                "* Set `stream_mode=\"updates\"` to get the output from each node as it completes.\n",
                "* Iterate through the stream and `pprint` each step's output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pprint import pprint\n",
                "\n",
                "for step in graph.stream(\n",
                "    {\"question\": \"list me all the courses in the A1-W domain that can teach me about social media data\"}, stream_mode=\"updates\"\n",
                "):\n",
                "    pprint(step)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ragenv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}